=============
INTRODUCTION
=============

The demo illustrates a simple use case of Oracle Table Access for Hadoop and 
Spark. It creates Hive external tables with different table properties to query 
Oracle Tables. We use simple and partition based splitters issue queries that 
do predicate pushdown while executing.

====================
System Requirements
====================

1. BDA 4.3 (or higher)
2. Oracle Database 12.1.0.2 (or higher)

==========
HOW TO RUN
==========

1. Extract ota4h_demo.zip to any location. Bash scripts to create tables and 
run queries are located under shell directory.

2. Execute createOracleTables.sh to create staging Oracle tables. You may have 
to set TWO_TASK environment variable before running this in order to create a 
table for a PDB user. 

3. Execute createHiveTables.sh to create Hive external tables for querying.

4. Execute any of *Query.sh script to execute a query on Hive external tables.

5. Use Apache/Cloudera tools to set logging levels and check out the queries 
generated by Oracle Storage Handler for querying Oracle tables.
